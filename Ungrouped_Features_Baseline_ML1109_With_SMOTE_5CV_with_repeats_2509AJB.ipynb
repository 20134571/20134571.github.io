{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6H0zD4fF14pmNV6hsyR3P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/20134571/20134571.github.io/blob/main/Ungrouped_Features_Baseline_ML1109_With_SMOTE_5CV_with_repeats_2509AJB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWpxNLVNug1p"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Sep 11 08:05:47 2025\n",
        "@author: heidi\n",
        "\"\"\"\n",
        "\n",
        "# ============================ STABILITY ============================\n",
        "import os\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# ============================ Imports ============================\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve, average_precision_score, confusion_matrix\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAS_XGB = True\n",
        "except Exception as e:\n",
        "    HAS_XGB = False\n",
        "    print(\"ℹ️ Skipping XGBoost (import failed):\", e)\n",
        "\n",
        "# ============================ Config ============================\n",
        "N_JOBS_PAR = 2\n",
        "PCA_VARIANCE = 0.95\n",
        "N_SPLITS = 5\n",
        "N_REPEATS = 3  # Number of repeats\n",
        "N_NEIGHBORS = 9\n",
        "\n",
        "# ============================ Load Data ============================\n",
        "url = \"https://raw.githubusercontent.com/20134571/AISKILLSET/main/airline_satisfaction_mitigation_arrival_cleaned.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "target_col = \"satisfaction\"\n",
        "drop_cols = [\"Unnamed: 0\", \"id\", \"Arrival Delay in Minutes\"]\n",
        "\n",
        "X = df.drop(columns=[c for c in drop_cols if c in df.columns] + [target_col]).copy()\n",
        "y = df[target_col].copy()\n",
        "\n",
        "cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
        "if cat_cols:\n",
        "    X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
        "\n",
        "def _sanitize(s: str) -> str:\n",
        "    s = str(s)\n",
        "    s = re.sub(r\"[^\\w]+\", \"_\", s)\n",
        "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
        "    return s\n",
        "\n",
        "X.columns = [_sanitize(c) for c in X.columns]\n",
        "\n",
        "# ============================ Helper Functions ============================\n",
        "def summarize(y_true, y_pred, name):\n",
        "    rep = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
        "    return {\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Prec_0\": rep[\"0\"][\"precision\"], \"Rec_0\": rep[\"0\"][\"recall\"], \"F1_0\": rep[\"0\"][\"f1-score\"],\n",
        "        \"Prec_1\": rep[\"1\"][\"precision\"], \"Rec_1\": rep[\"1\"][\"recall\"], \"F1_1\": rep[\"1\"][\"f1-score\"],\n",
        "        \"MacroF1\": (rep[\"0\"][\"f1-score\"] + rep[\"1\"][\"f1-score\"]) / 2,\n",
        "        \"WeightedF1\": rep[\"weighted avg\"][\"f1-score\"],\n",
        "    }\n",
        "\n",
        "def plot_roc_pr(models, y_test, title_suffix=\"\"):\n",
        "    plt.figure(figsize=(12,5))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    for name, model, X_in in models:\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_score = model.predict_proba(X_in)[:,1]\n",
        "        elif hasattr(model, \"decision_function\"):\n",
        "            y_score = model.decision_function(X_in)\n",
        "        else:\n",
        "            continue\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc:.3f})\")\n",
        "    plt.plot([0,1],[0,1],\"k--\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(f\"ROC Curve {title_suffix}\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    for name, model, X_in in models:\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_score = model.predict_proba(X_in)[:,1]\n",
        "        elif hasattr(model, \"decision_function\"):\n",
        "            y_score = model.decision_function(X_in)\n",
        "        else:\n",
        "            continue\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
        "        ap = average_precision_score(y_test, y_score)\n",
        "        plt.plot(recall, precision, label=f\"{name} (AP={ap:.3f})\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(f\"Precision-Recall Curve {title_suffix}\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_cm(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(4.8,4.2))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", cbar=False)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "    plt.xticks([0.5,1.5], [\"0 (Dissatisfied)\",\"1 (Satisfied)\"])\n",
        "    plt.yticks([0.5,1.5], [\"0 (Dissatisfied)\",\"1 (Satisfied)\"], rotation=0)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# ============================ Cross-Validation with Repeats ============================\n",
        "rows = []\n",
        "smote = SMOTE(random_state=42, k_neighbors=5)\n",
        "scaler = StandardScaler()\n",
        "pca = PCA(n_components=PCA_VARIANCE, random_state=42)\n",
        "\n",
        "rkf = RepeatedStratifiedKFold(n_splits=N_SPLITS, n_repeats=N_REPEATS, random_state=42)\n",
        "\n",
        "fold_num = 0\n",
        "for train_idx, test_idx in rkf.split(X, y):\n",
        "    fold_num += 1\n",
        "    repeat_num = ((fold_num-1) // N_SPLITS) + 1\n",
        "    split_num = ((fold_num-1) % N_SPLITS) + 1\n",
        "    print(f\"\\n===== Repeat {repeat_num}, Fold {split_num} =====\")\n",
        "\n",
        "    X_train, X_test = X.iloc[train_idx].copy(), X.iloc[test_idx].copy()\n",
        "    y_train, y_test = y.iloc[train_idx].copy(), y.iloc[test_idx].copy()\n",
        "\n",
        "    # Apply SMOTE\n",
        "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Scale\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # PCA\n",
        "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "    X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "    # ==================== Models ====================\n",
        "    knn_np = KNeighborsClassifier(n_neighbors=N_NEIGHBORS).fit(X_train_scaled, y_train_res)\n",
        "    rows.append(summarize(y_test, knn_np.predict(X_test_scaled), f\"KNN (Scaled, R{repeat_num}F{split_num})\"))\n",
        "\n",
        "    logreg_np = LogisticRegression(max_iter=1000, random_state=42).fit(X_train_scaled, y_train_res)\n",
        "    rows.append(summarize(y_test, logreg_np.predict(X_test_scaled), f\"LogReg (Scaled, R{repeat_num}F{split_num})\"))\n",
        "\n",
        "    svm_np = SVC(kernel='rbf', probability=True, random_state=42).fit(X_train_scaled, y_train_res)\n",
        "    rows.append(summarize(y_test, svm_np.predict(X_test_scaled), f\"SVM (Scaled, R{repeat_num}F{split_num})\"))\n",
        "\n",
        "    knn_pca = KNeighborsClassifier(n_neighbors=N_NEIGHBORS).fit(X_train_pca, y_train_res)\n",
        "    rows.append(summarize(y_test, knn_pca.predict(X_test_pca), f\"KNN (PCA, R{repeat_num}F{split_num})\"))\n",
        "\n",
        "    logreg_pca = LogisticRegression(max_iter=1000, random_state=42).fit(X_train_pca, y_train_res)\n",
        "    rows.append(summarize(y_test, logreg_pca.predict(X_test_pca), f\"LogReg (PCA, R{repeat_num}F{split_num})\"))\n",
        "\n",
        "    svm_pca = SVC(kernel='rbf', probability=True, random_state=42).fit(X_train_pca, y_train_res)\n",
        "    rows.append(summarize(y_test, svm_pca.predict(X_test_pca), f\"SVM (PCA, R{repeat_num}F{split_num})\"))\n",
        "\n",
        "    rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=N_JOBS_PAR)\n",
        "    rf.fit(X_train_res, y_train_res)\n",
        "    rows.append(summarize(y_test, rf.predict(X_test), f\"RF (Tabular, R{repeat_num}F{split_num})\"))\n",
        "\n",
        "    if HAS_XGB:\n",
        "        xgb_tab = XGBClassifier(\n",
        "            objective=\"binary:logistic\", eval_metric=\"logloss\", tree_method=\"hist\",\n",
        "            n_estimators=500, max_depth=6, learning_rate=0.1,\n",
        "            subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
        "            scale_pos_weight=1, random_state=42, n_jobs=N_JOBS_PAR\n",
        "        )\n",
        "        xgb_tab.fit(X_train_res, y_train_res)\n",
        "        rows.append(summarize(y_test, xgb_tab.predict(X_test), f\"XGB (Tabular, R{repeat_num}F{split_num})\"))\n",
        "\n",
        "    # Save last fold/repeat for visuals\n",
        "    if fold_num == N_SPLITS * N_REPEATS:\n",
        "        last_rf, last_svm, last_knn, last_logreg = rf, svm_np, knn_np, logreg_np\n",
        "        last_xgb = xgb_tab if HAS_XGB else None\n",
        "        last_y_test, last_X_test, last_X_test_scaled, last_X_train_res = y_test, X_test, X_test_scaled, X_train_res\n",
        "        last_scaler, last_pca = scaler, pca\n",
        "\n",
        "# ============================ Results ============================\n",
        "df_results = pd.DataFrame(rows)\n",
        "df_results.to_csv(\"model_results_rkf.csv\", index=False)\n",
        "\n",
        "df_results_grouped = df_results.groupby(df_results[\"Model\"].str.split(\" R\").str[0]).mean(numeric_only=True).round(3)\n",
        "print(\"\\n=== Average Results Across Folds & Repeats ===\")\n",
        "print(df_results_grouped.sort_values([\"Accuracy\",\"MacroF1\"], ascending=False))\n",
        "\n",
        "# ============================ Visualizations ============================\n",
        "# 1) Accuracy / MacroF1 Leaderboard\n",
        "df_plot = df_results[[\"Accuracy\",\"MacroF1\"]].copy().sort_values(\"Accuracy\", ascending=False)\n",
        "plt.figure(figsize=(10,5))\n",
        "df_plot[\"Accuracy\"].plot(kind=\"bar\")\n",
        "plt.title(\"Model Accuracy (higher is better, SMOTE applied)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xticks(rotation=20, ha=\"right\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "df_plot[\"MacroF1\"].plot(kind=\"bar\")\n",
        "plt.title(\"Model Macro-F1 (averaged F1 of both classes, SMOTE applied)\")\n",
        "plt.ylabel(\"Macro-F1\")\n",
        "plt.xticks(rotation=20, ha=\"right\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# 2) Confusion Matrices for last fold/repeat\n",
        "plot_cm(last_y_test, last_rf.predict(last_X_test), \"Confusion Matrix — RF (Tabular Non-PCA, SMOTE)\")\n",
        "if last_xgb is not None:\n",
        "    plot_cm(last_y_test, last_xgb.predict(last_X_test), \"Confusion Matrix — XGB (Tabular Non-PCA, SMOTE)\")\n",
        "plot_cm(last_y_test, last_svm.predict(last_X_test_scaled), \"Confusion Matrix — SVM (Scaled, SMOTE)\")\n",
        "\n",
        "# 3) Feature Importances\n",
        "rf_imp = (pd.DataFrame({\"Feature\": last_X_train_res.columns, \"Importance\": last_rf.feature_importances_})\n",
        "          .sort_values(\"Importance\", ascending=False).head(15))\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(data=rf_imp, x=\"Importance\", y=\"Feature\")\n",
        "plt.title(\"Top 15 RF Feature Importances (SMOTE)\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "if last_xgb is not None:\n",
        "    xgb_imp = (pd.DataFrame({\"Feature\": last_X_train_res.columns, \"Importance\": last_xgb.feature_importances_})\n",
        "               .sort_values(\"Importance\", ascending=False).head(15))\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.barplot(data=xgb_imp, x=\"Importance\", y=\"Feature\")\n",
        "    plt.title(\"Top 15 XGB Feature Importances (SMOTE)\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# 4) PCA Variance\n",
        "cum = np.cumsum(last_pca.explained_variance_ratio_)\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(range(1, len(cum)+1), cum, marker='o')\n",
        "plt.axhline(0.90, linestyle='--', label='90%')\n",
        "plt.axhline(0.95, linestyle='--', label='95%')\n",
        "plt.xlabel(\"Number of Components\"); plt.ylabel(\"Cumulative Explained Variance\")\n",
        "plt.title(\"PCA — Cumulative Explained Variance (SMOTE)\"); plt.legend(); plt.tight_layout(); plt.show()\n"
      ]
    }
  ]
}