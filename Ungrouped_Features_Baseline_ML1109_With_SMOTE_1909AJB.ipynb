{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqpx1HOJPuCgWwNP7tqfTC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/20134571/20134571.github.io/blob/main/Ungrouped_Features_Baseline_ML1109_With_SMOTE_1909AJB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "oxfwvEtspkoQ",
        "outputId": "81749b7c-40f1-47a8-9731-100e60805c2e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 400)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m400\u001b[0m\n\u001b[0;31m    plot_roc_pr(models_to_plot, y_test, title_suffix=\"— Airline Satisfaction\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Sep 11 08:05:47 2025\n",
        "\n",
        "@author: heidi\n",
        "\"\"\"\n",
        "\n",
        "# ============================ STABILITY (Windows/Spyder) ============================\n",
        "import os\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# ============================ Imports ============================\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "\n",
        "\n",
        "# SMOTE for synthetic data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# XGBoost (optional)\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    HAS_XGB = True\n",
        "except Exception as e:\n",
        "    HAS_XGB = False\n",
        "    print(\"ℹ️ Skipping XGBoost (import failed):\", e)\n",
        "\n",
        "# ============================ Config ============================\n",
        "N_JOBS_PAR = 2          # keep modest to avoid freezes\n",
        "PCA_VARIANCE = 0.95     # keep ~95% variance for PCA\n",
        "\n",
        "# ============================ 1) Load & basic clean ============================\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "url = \"https://raw.githubusercontent.com/20134571/AISKILLSET/main/airline_satisfaction_mitigation_arrival_cleaned.csv\"\n",
        "df = pd.read_csv(url)\n",
        "print (df)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "#df = pd.read_csv(\"airline_satisfaction_cleaned_ungrouped.csv\")\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "target_col = \"satisfaction\"\n",
        "drop_cols = [\"Unnamed: 0\", \"id\", \"Arrival Delay in Minutes\"]  # adjust if you want to keep arrival delay\n",
        "\n",
        "# ============================ 2) Build X, y ============================\n",
        "X = df.drop(columns=[c for c in drop_cols if c in df.columns] + [target_col]).copy()\n",
        "y = df[target_col].copy()\n",
        "\n",
        "# ---- Ensure numeric features: one-hot encode only if needed ----\n",
        "cat_cols = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
        "if cat_cols:\n",
        "    preview = cat_cols[:10]\n",
        "    print(f\"One-hot encoding {len(cat_cols)} categorical columns: {preview}{' ...' if len(cat_cols)>10 else ''}\")\n",
        "    X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
        "else:\n",
        "    print(\"No categorical columns detected — skipping one-hot encoding.\")\n",
        "\n",
        "# ---- Sanitize column names for XGBoost safety ----\n",
        "def _sanitize(s: str) -> str:\n",
        "    s = str(s)\n",
        "    s = re.sub(r\"[^\\w]+\", \"_\", s)    # replace non-alphanumerics with _\n",
        "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
        "    return s\n",
        "\n",
        "X.columns = [_sanitize(c) for c in X.columns]\n",
        "print(f\"Features after encoding: {X.shape[1]}\")\n",
        "\n",
        "# ============================ 3) Unified split (shared by all models) ============================\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n",
        "train_idx, test_idx = next(sss.split(X, y))\n",
        "\n",
        "X_train_tab = X.iloc[train_idx].copy()\n",
        "X_test_tab  = X.iloc[test_idx].copy()\n",
        "y_train = y.iloc[train_idx].copy()\n",
        "y_test  = y.iloc[test_idx].copy()\n",
        "\n",
        "# ============================ 3b) Apply SMOTE to training set ============================\n",
        "print(\"Original training set class distribution:\", y_train.value_counts().to_dict())\n",
        "\n",
        "smote = SMOTE(random_state=42, k_neighbors=5)\n",
        "X_train_tab_res, y_train_res = smote.fit_resample(X_train_tab, y_train)\n",
        "\n",
        "print(\"After SMOTE class distribution:\", pd.Series(y_train_res).value_counts().to_dict())\n",
        "\n",
        "# ============================ 3c) Scaled & PCA views ============================\n",
        "scaler = StandardScaler().fit(X_train_tab_res)\n",
        "X_train_scaled = scaler.transform(X_train_tab_res)\n",
        "X_test_scaled  = scaler.transform(X_test_tab)\n",
        "\n",
        "pca = PCA(n_components=PCA_VARIANCE, random_state=42).fit(X_train_scaled)\n",
        "X_train_pca = pca.transform(X_train_scaled)\n",
        "X_test_pca  = pca.transform(X_test_scaled)\n",
        "\n",
        "print(f\"PCA reduced features:    {X_train_pca.shape[1]}\")\n",
        "\n",
        "# ============================ 4) Train models (both PCA & non-PCA) ============================\n",
        "\n",
        "def summarize(y_true, y_pred, name):\n",
        "    rep = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
        "    return {\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Prec_0\": rep[\"0\"][\"precision\"], \"Rec_0\": rep[\"0\"][\"recall\"], \"F1_0\": rep[\"0\"][\"f1-score\"],\n",
        "        \"Prec_1\": rep[\"1\"][\"precision\"], \"Rec_1\": rep[\"1\"][\"recall\"], \"F1_1\": rep[\"1\"][\"f1-score\"],\n",
        "        \"MacroF1\": (rep[\"0\"][\"f1-score\"] + rep[\"1\"][\"f1-score\"]) / 2,\n",
        "        \"WeightedF1\": rep[\"weighted avg\"][\"f1-score\"],\n",
        "    }\n",
        "\n",
        "rows = []\n",
        "\n",
        "# ---------- Non-PCA (scaled) ----------\n",
        "knn_np = KNeighborsClassifier(n_neighbors=9).fit(X_train_scaled, y_train_res)\n",
        "rows.append(summarize(y_test, knn_np.predict(X_test_scaled), \"KNN (Non-PCA, Scaled)\"))\n",
        "\n",
        "logreg_np = LogisticRegression(max_iter=1000, random_state=42).fit(X_train_scaled, y_train_res)\n",
        "rows.append(summarize(y_test, logreg_np.predict(X_test_scaled), \"LogReg (Non-PCA, Scaled)\"))\n",
        "\n",
        "svm_np = SVC(kernel='rbf', random_state=42).fit(X_train_scaled, y_train_res)\n",
        "rows.append(summarize(y_test, svm_np.predict(X_test_scaled), \"SVM (Non-PCA, Scaled)\"))\n",
        "\n",
        "# ---------- PCA ----------\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=9).fit(X_train_pca, y_train_res)\n",
        "rows.append(summarize(y_test, knn_pca.predict(X_test_pca), \"KNN (PCA)\"))\n",
        "\n",
        "logreg_pca = LogisticRegression(max_iter=1000, random_state=42).fit(X_train_pca, y_train_res)\n",
        "rows.append(summarize(y_test, logreg_pca.predict(X_test_pca), \"LogReg (PCA)\"))\n",
        "\n",
        "svm_pca = SVC(kernel='rbf', random_state=42).fit(X_train_pca, y_train_res)\n",
        "rows.append(summarize(y_test, svm_pca.predict(X_test_pca), \"SVM (PCA)\"))\n",
        "\n",
        "# ---------- Random Forest (NON-PCA ONLY) ----------\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=N_JOBS_PAR)\n",
        "rf.fit(X_train_tab_res, y_train_res)\n",
        "rows.append(summarize(y_test, rf.predict(X_test_tab), \"RF (Tabular Non-PCA)\"))\n",
        "\n",
        "# ---------- XGBoost (both Tabular and PCA) ----------\n",
        "if HAS_XGB:\n",
        "    # Balanced dataset after SMOTE -> scale_pos_weight = 1\n",
        "    xgb_tab = XGBClassifier(\n",
        "        objective=\"binary:logistic\", eval_metric=\"logloss\", tree_method=\"hist\",\n",
        "        n_estimators=500, max_depth=6, learning_rate=0.1,\n",
        "        subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
        "        scale_pos_weight=1, random_state=42, n_jobs=N_JOBS_PAR\n",
        "    )\n",
        "    xgb_tab.fit(X_train_tab_res, y_train_res)\n",
        "    rows.append(summarize(y_test, xgb_tab.predict(X_test_tab), \"XGB (Tabular Non-PCA)\"))\n",
        "\n",
        "    xgb_pca = XGBClassifier(\n",
        "        objective=\"binary:logistic\", eval_metric=\"logloss\", tree_method=\"hist\",\n",
        "        n_estimators=500, max_depth=6, learning_rate=0.1,\n",
        "        subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,\n",
        "        scale_pos_weight=1, random_state=42, n_jobs=N_JOBS_PAR\n",
        "    )\n",
        "    xgb_pca.fit(X_train_pca, y_train_res)\n",
        "    rows.append(summarize(y_test, xgb_pca.predict(X_test_pca), \"XGB (PCA)\"))\n",
        "\n",
        "# ============================ 5) Results table ============================\n",
        "df_results = pd.DataFrame(rows).set_index(\"Model\").round(3)\n",
        "print(\"\\n=== Results (Both PCA & Non-PCA; RF Non-PCA only, with SMOTE) ===\")\n",
        "print(df_results.sort_values([\"Accuracy\", \"MacroF1\"], ascending=False))\n",
        "\n",
        "# (Optional) save to CSV\n",
        "# df_results.to_csv(\"results_pca_vs_nonpca_smote.csv\")\n",
        "\n",
        "\n",
        "# ========================= VISUALIZATIONS =========================\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ---------- 1) Leaderboard: Accuracy & MacroF1 ----------\n",
        "df_plot = df_results[[\"Accuracy\", \"MacroF1\"]].copy().sort_values(\"Accuracy\", ascending=False)\n",
        "plt.figure(figsize=(10,5))\n",
        "df_plot[\"Accuracy\"].plot(kind=\"bar\")\n",
        "plt.title(\"Model Accuracy (higher is better, SMOTE applied)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xticks(rotation=20, ha=\"right\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "df_plot[\"MacroF1\"].plot(kind=\"bar\")\n",
        "plt.title(\"Model Macro-F1 (averaged F1 of both classes, SMOTE applied)\")\n",
        "plt.ylabel(\"Macro-F1\")\n",
        "plt.xticks(rotation=20, ha=\"right\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# ---------- 2) Confusion matrices for top performers ----------\n",
        "def plot_cm(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(4.8,4.2))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", cbar=False)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "    plt.xticks([0.5,1.5], [\"0 (Dissatisfied)\",\"1 (Satisfied)\"])\n",
        "    plt.yticks([0.5,1.5], [\"0 (Dissatisfied)\",\"1 (Satisfied)\"], rotation=0)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "plot_cm(y_test, rf.predict(X_test_tab), \"Confusion Matrix — RF (Tabular Non-PCA, SMOTE)\")\n",
        "try:\n",
        "    plot_cm(y_test, xgb_tab.predict(X_test_tab), \"Confusion Matrix — XGB (Tabular Non-PCA, SMOTE)\")\n",
        "except NameError:\n",
        "    pass\n",
        "plot_cm(y_test, svm_np.predict(X_test_scaled), \"Confusion Matrix — SVM (Non-PCA, Scaled, SMOTE)\")\n",
        "\n",
        "# ---------- 3) Feature importances (RF & XGB) ----------\n",
        "rf_imp = (pd.DataFrame({\"Feature\": X_train_tab_res.columns, \"Importance\": rf.feature_importances_})\n",
        "          .sort_values(\"Importance\", ascending=False).head(15))\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(data=rf_imp, x=\"Importance\", y=\"Feature\")\n",
        "plt.title(\"Top 15 RF Feature Importances (SMOTE)\")\n",
        "plt.tight_layout(); plt.show()\n",
        "print(\"\\nTop RF features:\\n\", rf_imp)\n",
        "\n",
        "try:\n",
        "    xgb_imp = (pd.DataFrame({\"Feature\": X_train_tab_res.columns, \"Importance\": xgb_tab.feature_importances_})\n",
        "               .sort_values(\"Importance\", ascending=False).head(15))\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.barplot(data=xgb_imp, x=\"Importance\", y=\"Feature\")\n",
        "    plt.title(\"Top 15 XGB Feature Importances (SMOTE)\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "    print(\"\\nTop XGB features:\\n\", xgb_imp)\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "# ---------- 4) PCA visuals (explained variance, loadings, scatter) ----------\n",
        "cum = np.cumsum(pca.explained_variance_ratio_)\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(range(1, len(cum)+1), cum, marker='o')\n",
        "plt.axhline(0.90, linestyle='--', label='90%')\n",
        "plt.axhline(0.95, linestyle='--', label='95%')\n",
        "plt.xlabel(\"Number of Components\"); plt.ylabel(\"Cumulative Explained Variance\")\n",
        "plt.title(\"PCA — Cumulative Explained Variance (SMOTE)\"); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "loadings = pd.DataFrame(\n",
        "    pca.components_.T,\n",
        "    index=X_train_tab_res.columns,\n",
        "    columns=[f\"PC{i+1}\" for i in range(pca.n_components_)]\n",
        ")\n",
        "for pc in [\"PC1\", \"PC2\"]:\n",
        "    if pc in loadings.columns:\n",
        "        top = loadings[pc].abs().sort_values(ascending=False).head(12)\n",
        "        plt.figure(figsize=(8,6))\n",
        "        sns.barplot(x=top.values, y=top.index, orient=\"h\")\n",
        "        plt.title(f\"Top {len(top)} Feature Contributions to {pc} (|loading|, SMOTE)\")\n",
        "        plt.xlabel(\"Absolute Loading\"); plt.ylabel(\"Feature\")\n",
        "        plt.tight_layout(); plt.show()\n",
        "\n",
        "X_scaled_all = scaler.transform(X)\n",
        "PC_all = pca.transform(X_scaled_all)\n",
        "plt.figure(figsize=(6.2,5.4))\n",
        "plt.scatter(PC_all[:,0], PC_all[:,1], c=y, alpha=0.35, s=14)\n",
        "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.title(\"PC1 vs PC2 (colored by satisfaction, SMOTE)\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# ---------- 5) (Optional) Probability histograms ----------\n",
        "def prob_hist(model, X_te, y_te, title):\n",
        "    if not hasattr(model, \"predict_proba\"):\n",
        "        return\n",
        "    p = model.predict_proba(X_te)[:,1]\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.hist(p[y_te==0], bins=30, alpha=0.6, label=\"Class 0\", density=True)\n",
        "    plt.hist(p[y_te==1], bins=30, alpha=0.6, label=\"Class 1\", density=True)\n",
        "    plt.xlabel(\"Predicted probability for class 1\"); plt.ylabel(\"Density\")\n",
        "    plt.title(title); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "prob_hist(rf, X_test_tab, y_test, \"RF — Probability Distribution by True Class (SMOTE)\")\n",
        "try:\n",
        "    prob_hist(xgb_tab, X_test_tab, y_test, \"XGB — Probability Distribution by True Class (SMOTE)\")\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "#====================ROC Curve and PR Curve====================#\n",
        "\n",
        "def plot_roc_pr(models, y_test, title_suffix=\"\"):\n",
        "    plt.figure(figsize=(12,5))\n",
        "\n",
        "    # ---- ROC curve ----\n",
        "    plt.subplot(1,2,1)\n",
        "    for name, model, X in models:\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_score = model.predict_proba(X)[:,1]\n",
        "        elif hasattr(model, \"decision_function\"):\n",
        "            y_score = model.decision_function(X)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc:.3f})\")\n",
        "\n",
        "    plt.plot([0,1],[0,1],\"k--\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate (Recall)\")\n",
        "    plt.title(f\"ROC Curve {title_suffix}\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    # ---- Precision-Recall curve ----\n",
        "    plt.subplot(1,2,2)\n",
        "    for name, model, X in models:\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            y_score = model.predict_proba(X)[:,1]\n",
        "        elif hasattr(model, \"decision_function\"):\n",
        "            y_score = model.decision_function(X)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
        "        ap = average_precision_score(y_test, y_score)\n",
        "        plt.plot(recall, precision, label=f\"{name} (AP={ap:.3f})\")\n",
        "\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(f\"Precision-Recall Curve {title_suffix}\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_roc_pr(models_to_plot, y_test, title_suffix=\"— Airline Satisfaction\")\n",
        "\n",
        "#======cross-check this with permutation importance========#\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# List of models to check\n",
        "models = {\n",
        "    \"Random Forest\": rf,\n",
        "}\n",
        "\n",
        "# Add XGB if available\n",
        "try:\n",
        "    models[\"XGBoost\"] = xgb_tab\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "# Store results\n",
        "perm_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    r = permutation_importance(\n",
        "        model,\n",
        "        X_test_tab,    # Use same test set for fair comparison\n",
        "        y_test,\n",
        "        n_repeats=10,  # number of shuffles\n",
        "        random_state=42,\n",
        "        scoring=\"accuracy\"  # you can also use \"roc_auc\"\n",
        "    )\n",
        "    perm_results[name] = pd.DataFrame({\n",
        "        \"Feature\": X_test_tab.columns,\n",
        "        \"Importance\": r.importances_mean\n",
        "    }).sort_values(\"Importance\", ascending=False)\n",
        "\n",
        "# Display top 10 features for each model\n",
        "for name, df_perm in perm_results.items():\n",
        "    print(f\"\\nTop 10 features by permutation importance — {name}:\")\n",
        "    display(df_perm.head(10))\n",
        "\n",
        "# Optional: plot comparison for Online boarding\n",
        "plt.figure(figsize=(6,4))\n",
        "online_boarding_vals = [perm_results[m].loc[perm_results[m][\"Feature\"]==\"Inflight online boarding\",\"Importance\"].values[0]\n",
        "                        for m in perm_results]\n",
        "plt.bar(perm_results.keys(), online_boarding_vals, color=[\"#4c72b0\", \"#55a868\"])\n",
        "plt.ylabel(\"Permutation Importance\")\n",
        "plt.title(\"Online Boarding Feature Importance Comparison (RF vs XGB)\")\n",
        "plt.show()\n"
      ]
    }
  ]
}